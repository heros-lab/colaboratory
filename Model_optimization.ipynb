{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heros-lab/colaboratory/blob/master/Model_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJLFfAg-Mvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdf69e96-142e-4c9f-c5e7-61421b7f359d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration import KerasPruningCallback\n",
        "\n",
        "work_path = \"/content/drive/My Drive/Colab Notebooks\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/32/266d4afd269e3ecd7fcc595937c1733f65eae6c09c3caea74c0de0b88d78/optuna-1.5.0.tar.gz (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.7MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/59/4db149d8962dc29a37c8bc08cd79185935527af9a27259a2d80cac707212/cliff-3.3.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/03/de/6ed34ebc0e5c34ed371d898540bca36edb4afe5bb2ca382483054e573c75/cmaes-0.5.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/00/0d/22c73c2eccb21dd3498df7d22c0b1d4a30f5a5fb3feb64e1ce06bc247747/colorlog-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.17)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.12.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting stevedore>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/75/154f7b0bc00a580db2ccac141400dc601f7f2a1bf45bd56515edbda34850/stevedore-2.0.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/b2/440d8d89b432b250c8f4db4368301aa7c6b49ab48a87b42e2a36f60c104d/cmd2-1.1.0-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (47.3.1)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=bb5897da7ab95e220d59787ba8195cd6c3e86c2c4738fd9e7c1f0c802027b13c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-1.5.0-cp36-none-any.whl size=276145 sha256=c080987051b91e6db067993fdd54939af5aa4930e3679d861688cbee69c4b0b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/21/78/4f5529e0c757ababc4217eb9adf1886d21eb22bb1ab98c33c5\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=d70cd0f16d9ed97072238f540612f44b117782e717186de9dc6b88b8afd5182a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, pbr, stevedore, pyperclip, colorama, cmd2, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.3.0 cmaes-0.5.0 cmd2-1.1.0 colorama-0.4.3 colorlog-4.1.0 optuna-1.5.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4MWBcF_85AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class optimize_manager:\n",
        "    def __init__(self, max_units, study_name):\n",
        "        self.max_units = max_units\n",
        "        self.score_path  = f\"{work_path}/score_{study_name}.csv\"\n",
        "        self.result_path = f\"{work_path}/result_{study_name}.csv\"\n",
        "\n",
        "    def filtering_with_IQR(self, data_list):\n",
        "        pd_series = pd.Series(data_list)\n",
        "        q1 = pd_series.quantile(.25)\n",
        "        q3 = pd_series.quantile(.75)\n",
        "        iqr = q3 - q1\n",
        "        lim_upper = q3 + iqr*1.5\n",
        "        lim_lower = q1 - iqr*1.5\n",
        "        return pd_series[pd_series.apply(lambda x:lim_lower < x < lim_upper)]    \n",
        "\n",
        "    def save_scores(self, count, units, data_list):\n",
        "        with open(self.score_path, \"w\" if count == 0 else \"a\") as file:\n",
        "            file.write(f\"#{count}\")\n",
        "            for num_unit in units:\n",
        "                file.write(f\", {num_unit}\")\n",
        "            for data in data_list:\n",
        "                file.write(f\", {data:.6e}\")\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "    def save_results(self, trial_id, units, samples, mean, std, mean_f, std_f):\n",
        "        if trial_id == 0:\n",
        "            mode = \"w\"\n",
        "            header = \"Trials\"\n",
        "            for i in range(len(units)):\n",
        "                header += f\", Unit-{i+1}\"\n",
        "            header += \", Samples(Full:101), Estimated loss, Standard-deviation, Estimated loss(filter), Standard-deviation(filter)\\n\"\n",
        "        else:\n",
        "            mode = \"a\"\n",
        "            header = \"\"\n",
        "\n",
        "        with open(self.result_path, mode) as file:\n",
        "            file.write(header)\n",
        "            file.write(f\"#{trial_id}\")\n",
        "            for num_unit in units:\n",
        "                file.write(f\", {num_unit}\")\n",
        "            file.write(f\", {samples}, {mean:.6e}, {std:.6e}, {mean_f:.6e}, {std_f:.6e}\\n\")\n",
        "\n",
        "    def objective(self, trial):\n",
        "        epochs = 200\n",
        "        num_batch = 1024\n",
        "        num_sample = 101\n",
        "        num_units  = [trial.suggest_int(f\"num_unit{i+1}\", 1, self.max_units[i]) for i in range(len(self.max_units))]\n",
        "\n",
        "        score_list = []\n",
        "        for i in range(num_sample):\n",
        "            clear_session()\n",
        "            print(f\"\\r#{trial.number:2} -- unit: {num_units}, sampling: {i+1}/{num_sample}\", end=\"\")\n",
        "            \n",
        "            model = Sequential()\n",
        "            model.add(Dense(\n",
        "                    input_dim=learn_x.shape[1], units=num_units[0],\n",
        "                    activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "            for i in range(len(num_units) - 1):\n",
        "                model.add(Dense(\n",
        "                    input_dim=num_units[i], units=num_units[i+1],\n",
        "                    activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "            model.add(Dense(input_dim=num_units[-1], units=1))\n",
        "            model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
        "            model.fit(learn_x, learn_y, batch_size=num_batch, epochs=epochs, verbose=0)\n",
        "\n",
        "            score = model.evaluate(test_x, test_y, batch_size=test_x.shape[0], verbose=0)\n",
        "            score_list.append(score)\n",
        "        \n",
        "        # フィルタ処理\n",
        "        score_list_flt = self.filtering_with_IQR(score_list)\n",
        "        \n",
        "        # 平均と標準偏差の算出\n",
        "        mean, std = pd.Series(score_list).describe().loc[[\"mean\",\"std\"]]        \n",
        "        samples, mean_f, std_f = score_list_flt.describe().loc[[\"count\",\"mean\",\"std\"]]\n",
        "        \n",
        "        # 保存＆結果出力\n",
        "        self.save_scores(trial.number, num_units, score_list)\n",
        "        self.save_results(trial.number, num_units, samples, mean, std, mean_f, std_f)\n",
        "        print(f\"\\r#{trial.number:2} -- unit: {num_units}, samples: {samples}/101, mean: {mean:.4e}, std: {std:.4e}\")\n",
        "\n",
        "        return mean"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLZiBtuaZBIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_name = \"ms3a\"\n",
        "test_name  = \"ms2a\"\n",
        "\n",
        "df_learn_x = pd.read_csv(f\"{work_path}/data/{learn_name}_x.csv\")\n",
        "df_learn_y = pd.read_csv(f\"{work_path}/data/{learn_name}_y.csv\")\n",
        "\n",
        "df_test_x = pd.read_csv(f\"{work_path}/data/{test_name}_x.csv\")\n",
        "df_test_y = pd.read_csv(f\"{work_path}/data/{test_name}_y.csv\")\n",
        "\n",
        "x_cols = list(df_learn_x.columns)\n",
        "y_cols = list(df_learn_y.columns)\n",
        "x_cols.remove(\"Time[sec]\")\n",
        "y_cols.remove(\"Time[sec]\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLnWVIbO_J40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_index = [0,1,2,3,4,5,6]   # index for conv.\n",
        "#x_index = [0,3,4,6]    # index for prop.1\n",
        "#x_index = [1,2,5,6]    # index for prop.2\n",
        "#x_index = [1,2,5,6]    # index for prop.3\n",
        "#x_index = [0,3,4,5,6]  # index for prop.4\n",
        "y_index = [3]\n",
        "\n",
        "learn_x = df_learn_x[x_cols].values[:, x_index]\n",
        "learn_y = df_learn_y[y_cols].values[:, y_index]\n",
        "test_x = df_test_x[x_cols].values[:, x_index]\n",
        "test_y = df_test_y[y_cols].values[:, y_index]\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZCEHBSEvRbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6050b383-bb09-4962-9bb6-68d117020f9a"
      },
      "source": [
        "tag = \"conv4\"\n",
        "ver = \"0.1\"\n",
        "max_units = [200, 200]\n",
        "\n",
        "STUDY_LOADING = False\n",
        "\n",
        "storage_path = f\"sqlite:///{work_path}/opt_model_{tag}.db\"\n",
        "study_name = tag + \"_ver\" + ver\n",
        "manager = optimize_manager(max_units, study_name)\n",
        "\n",
        "\n",
        "# study load or create\n",
        "if STUDY_LOADING:\n",
        "    study = optuna.load_study(study_name, storage_path, pruner=optuna.pruners.MedianPruner())\n",
        "else:\n",
        "    study = optuna.create_study(study_name=study_name, storage=storage_path, direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-06-20 11:40:18,917] A new study created with name: conv4_ver0.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHoh1z78I6z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e39a2ae9-87ab-4bc0-e07a-44d266c50097"
      },
      "source": [
        "study.optimize(manager.objective, n_trials=10)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"*** All Trial are finished!! ***\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0 -- unit: [51, 137], sampling: 4/101"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPTsIqaoflro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}