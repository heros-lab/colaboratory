{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heros-lab/colaboratory/blob/master/Model_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJLFfAg-Mvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7edf6460-12ed-423b-b578-85f2a6d3f0cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration import KerasPruningCallback\n",
        "\n",
        "work_path = \"/content/drive/My Drive/Colab Notebooks\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/32/266d4afd269e3ecd7fcc595937c1733f65eae6c09c3caea74c0de0b88d78/optuna-1.5.0.tar.gz (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.6MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/59/4db149d8962dc29a37c8bc08cd79185935527af9a27259a2d80cac707212/cliff-3.3.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/63/88/d5e9b78151dce671d7e78ee4cc8905d83208254caa2a386b163ae0ab0027/cmaes-0.6.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.18)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 31.0MB/s \n",
            "\u001b[?25hCollecting stevedore>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/f4/041afc90e684f2b7d00a7f49abcbaf0b8c03e916bbc398ce49dce2a3c408/stevedore-3.2.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/17/641b563f5839c61a4767a070644ff2be3f70fe0d8ddd879a52dbd4976980/cmd2-1.2.1-py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=1.20.0->cliff->optuna) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=1.20.0->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=540a02740da7d172f309e90483b1e5dbed84c6893ea2ba246c9aca0819e484e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-1.5.0-cp36-none-any.whl size=276145 sha256=ec289489a9b2505ed79095fc729fedefe2405601a0c444fe3e93ccc90654b096\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/21/78/4f5529e0c757ababc4217eb9adf1886d21eb22bb1ab98c33c5\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=9c22ef51c364a25952ef714568d7e2ce1b3a1ffba8ba5b23a31395a6b9f915ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: python-editor, Mako, alembic, pbr, stevedore, pyperclip, colorama, cmd2, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.3.0 cmaes-0.6.0 cmd2-1.2.1 colorama-0.4.3 colorlog-4.2.1 optuna-1.5.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7selOChVa0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetClass:\n",
        "    def __init__(self, data_path):\n",
        "        self.path = data_path\n",
        "    \n",
        "    def __reflect_index(self, data, index):\n",
        "        if index != None:\n",
        "            data = data[:, index]\n",
        "        return data\n",
        "        \n",
        "    def __load_df(self, data_label):\n",
        "        data_x = pd.read_csv(f\"{self.path}/{data_label}_nx.csv\", index_col=0)\n",
        "        data_y = pd.read_csv(f\"{self.path}/{data_label}_ny.csv\", index_col=0)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_data(self, data_label, x_index, y_index):\n",
        "        data_x, data_y = self.__load_df(data_label)\n",
        "        data_x = self.__reflect_index(data_x.values, x_index)\n",
        "        data_y = self.__reflect_index(data_y.values, y_index)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_stack(self, dataset_list, x_index, y_index):\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_data(label, x_index, y_index)\n",
        "            if dataset_list.index(label) == 0:\n",
        "                data_x = tmp_x\n",
        "                data_y = tmp_y\n",
        "            else:\n",
        "                data_x = np.vstack((data_x, tmp_x))\n",
        "                data_y = np.vstack((data_y, tmp_y))\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_dict(self, dataset_list, x_index, y_index):\n",
        "        data_x, data_y = {}, {}\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_data(label, x_index, y_index)\n",
        "            data_x[label] = tmp_x\n",
        "            data_y[label] = tmp_y\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def get_data(self, dataset_label, x_index=None, y_index=None, dict_type:bool=False):\n",
        "        if not dict_type:\n",
        "            if type(dataset_label) == str:\n",
        "                data_x, data_y = self.__load_data(dataset_label, x_index, y_index)\n",
        "            else:\n",
        "                data_x, data_y = self.__load_stack(dataset_label, x_index, y_index)\n",
        "        else:\n",
        "            data_x, data_y = self.__load_dict(dataset_label, x_index, y_index)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def get_dataframe(self, dataset_list):\n",
        "        data_x = {}\n",
        "        data_y = {}\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_df(label)\n",
        "            data_x[label] = tmp_x\n",
        "            data_y[label] = tmp_y\n",
        "        return data_x, data_y\n",
        "\n",
        "\n",
        "def set_index(model_type):\n",
        "    if \"conv.\" in model_type:\n",
        "        x_index = [i for i in range(7)]\n",
        "    elif model_type == \"prop.1\":\n",
        "        x_index = [0,3,4,6]\n",
        "    elif model_type == \"prop.2\":\n",
        "        x_index = [1,2,5,6]\n",
        "    elif model_type == \"prop.3\":\n",
        "        x_index = [1,2,5,6]\n",
        "    elif model_type == \"prop.4\":\n",
        "        x_index = [0,3,4,5,6]\n",
        "    else:\n",
        "        print(f\"<< {model_type} >> This model is not exist.\")\n",
        "    y_index = [int(model_type[-1])-1]\n",
        "    return x_index, y_index\n",
        "\n",
        "\n",
        "def set_dataset_label(model_type):\n",
        "    type_id = int(model_type[-1])\n",
        "    if type_id == 1:\n",
        "        learn = \"ms1a\"\n",
        "        test = \"ms2a\"\n",
        "    elif type_id == 2:\n",
        "        learn = \"ms3a\"\n",
        "        test = \"ms1a\"\n",
        "    elif type_id == 3:\n",
        "        learn = \"ms2a\"\n",
        "        test = \"ms3a\"\n",
        "    elif type_id == 4:\n",
        "        learn = \"ms3a\"\n",
        "        test = \"ms1a\"\n",
        "    return learn, test\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4MWBcF_85AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    max_unit = 100\n",
        "    batch_size = 512\n",
        "    #element = \n",
        "    epochs = 200\n",
        "    sample = 31\n",
        "    \n",
        "    num_unit1 = trial.suggest_int(f\"num_unit1\", 1, max_unit)\n",
        "    #max_unit2 = int((element - learn_x.shape[1]*num_unit1)/(num_unit1 + 1)) if max_unit2 <= max_unit else max_unit\n",
        "    #num_unit2 = trial.suggest_int(f\"num_unit2\", 1, max_unit2)\n",
        "    num_unit2 = trial.suggest_int(f\"num_unit2\", 1, max_unit)\n",
        "    num_units  = [num_unit1, num_unit2]\n",
        "\n",
        "    score_list = []\n",
        "    for i in range(sample):\n",
        "        clear_session()\n",
        "        print(f\"\\r#{trial.number:2} -- unit: {num_units}, sampling: {i+1}/{sample}\", end=\"\")\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Dense(\n",
        "                input_dim=learn_x.shape[1], units=num_units[0],\n",
        "                activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "        for i in range(len(num_units) - 1):\n",
        "            model.add(Dense(\n",
        "                input_dim=num_units[i], units=num_units[i+1],\n",
        "                activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "        model.add(Dense(input_dim=num_units[-1], units=1))\n",
        "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
        "        model.fit(learn_x, learn_y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "        score = model.evaluate(test_x, test_y, batch_size=test_x.shape[0], verbose=0)\n",
        "        score_list.append(score)\n",
        "            \n",
        "    mean, std = pd.Series(score_list).describe().loc[[\"mean\",\"std\"]]        \n",
        "    print(f\"\\r#{trial.number:2} -- unit: {num_units}, samples: {samples}/101, mean: {mean:.4e}, std: {std:.4e}\")\n",
        "\n",
        "    return mean"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPTsIqaoflro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d7aaab6d-1b60-4862-d4c7-cddac488144a"
      },
      "source": [
        "model_tag = \"conv.1\"\n",
        "data_path = f\"{work_path}/data/norms2\"\n",
        "\n",
        "x_index, y_index = set_index(model_tag)\n",
        "learn_list, test_list  = set_dataset_label(model_tag)\n",
        "\n",
        "dataset = DatasetClass(data_path)\n",
        "learn_x, learn_y = dataset.get_data(learn_list, x_index, y_index)\n",
        "test_x, test_y = dataset.get_data(test_list, x_index, y_index)\n",
        "\n",
        "print(f\"x_index: {x_index}, y_index: [{y_index[0]}]\")\n",
        "print(f\"learn list: {learn_list}, test_list: {test_list}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_index: [0, 1, 2, 3, 4, 5, 6], y_index: [0]\n",
            "learn list: ms1a, test_list: ms2a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-aAo7mWYbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60af36ec-2eea-4e97-cf65-06cee2789ec4"
      },
      "source": [
        "study_label = \"ver1.1\"\n",
        "STUDY_LOADING = False\n",
        "\n",
        "storage_path = f\"sqlite:///optimize_{model_tag}.db\"\n",
        "study_name = model_tag + \"_\" + study_label\n",
        "\n",
        "# study load or create\n",
        "if STUDY_LOADING:\n",
        "    study = optuna.load_study(study_name, storage_path, pruner=optuna.pruners.MedianPruner())\n",
        "else:\n",
        "    study = optuna.create_study(study_name=study_name, storage=storage_path, direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-07-28 17:03:37,244] A new study created with name: conv.1_ver1.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1fApkgAXtZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c1f7019-ccf5-4870-91cd-75418a062fc3"
      },
      "source": [
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"*** All Trial are finished!! ***\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0 -- unit: [46, 83], sampling: 6/31"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLSArSbX5RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}