{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heros-lab/colaboratory/blob/master/Model_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJLFfAg-Mvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration import KerasPruningCallback\n",
        "\n",
        "work_path = \"/content/drive/My Drive/Colab Notebooks\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7selOChVa0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetClass:\n",
        "    def __init__(self, data_path):\n",
        "        self.path = data_path\n",
        "    \n",
        "    def __reflect_index(self, data, index):\n",
        "        if index != None:\n",
        "            data = data[:, index]\n",
        "        return data\n",
        "        \n",
        "    def __load_df(self, data_label):\n",
        "        data_x = pd.read_csv(f\"{self.path}/{data_label}_nx.csv\", index_col=0)\n",
        "        data_y = pd.read_csv(f\"{self.path}/{data_label}_ny.csv\", index_col=0)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_data(self, data_label, x_index, y_index):\n",
        "        data_x, data_y = self.__load_df(data_label)\n",
        "        data_x = self.__reflect_index(data_x.values, x_index)\n",
        "        data_y = self.__reflect_index(data_y.values, y_index)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_stack(self, dataset_list, x_index, y_index):\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_data(label, x_index, y_index)\n",
        "            if dataset_list.index(label) == 0:\n",
        "                data_x = tmp_x\n",
        "                data_y = tmp_y\n",
        "            else:\n",
        "                data_x = np.vstack((data_x, tmp_x))\n",
        "                data_y = np.vstack((data_y, tmp_y))\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_dict(self, dataset_list, x_index, y_index):\n",
        "        data_x, data_y = {}, {}\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_data(label, x_index, y_index)\n",
        "            data_x[label] = tmp_x\n",
        "            data_y[label] = tmp_y\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def get_data(self, dataset_label, x_index=None, y_index=None, dict_type:bool=False):\n",
        "        if not dict_type:\n",
        "            if type(dataset_label) == str:\n",
        "                data_x, data_y = self.__load_data(dataset_label, x_index, y_index)\n",
        "            else:\n",
        "                data_x, data_y = self.__load_stack(dataset_label, x_index, y_index)\n",
        "        else:\n",
        "            data_x, data_y = self.__load_dict(dataset_label, x_index, y_index)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def get_dataframe(self, dataset_list):\n",
        "        data_x = {}\n",
        "        data_y = {}\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_df(label)\n",
        "            data_x[label] = tmp_x\n",
        "            data_y[label] = tmp_y\n",
        "        return data_x, data_y\n",
        "\n",
        "\n",
        "def set_index(model_type):\n",
        "    if \"conv.\" in model_type:\n",
        "        x_index = [i for i in range(7)]\n",
        "    elif model_type == \"prop.1\":\n",
        "        x_index = [0,3,4,6]\n",
        "    elif model_type == \"prop.2\":\n",
        "        x_index = [1,2,5,6]\n",
        "    elif model_type == \"prop.3\":\n",
        "        x_index = [1,2,5,6]\n",
        "    elif model_type == \"prop.4\":\n",
        "        x_index = [0,3,4,5,6]\n",
        "    else:\n",
        "        print(f\"<< {model_type} >> This model is not exist.\")\n",
        "    y_index = [int(model_type[-1])-1]\n",
        "    return x_index, y_index\n",
        "\n",
        "\n",
        "def set_dataset_label(model_type):\n",
        "    type_id = int(model_type[-1])\n",
        "    if type_id == 1:\n",
        "        learn = \"ms1a\"\n",
        "        test = \"ms2a\"\n",
        "    elif type_id == 2:\n",
        "        learn = \"ms3a\"\n",
        "        test = \"ms1a\"\n",
        "    elif type_id == 3:\n",
        "        learn = \"ms2a\"\n",
        "        test = \"ms3a\"\n",
        "    elif type_id == 4:\n",
        "        learn = \"ms3a\"\n",
        "        test = \"ms1a\"\n",
        "    return learn, test\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4MWBcF_85AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    max_unit = 100\n",
        "    batch_size = 512\n",
        "    #element = \n",
        "    epochs = 200\n",
        "    sample = 31\n",
        "    \n",
        "    num_unit1 = trial.suggest_int(f\"num_unit1\", 1, max_unit)\n",
        "    #max_unit2 = int((element - learn_x.shape[1]*num_unit1)/(num_unit1 + 1)) if max_unit2 <= max_unit else max_unit\n",
        "    #num_unit2 = trial.suggest_int(f\"num_unit2\", 1, max_unit2)\n",
        "    num_unit2 = trial.suggest_int(f\"num_unit2\", 1, max_unit)\n",
        "    num_units  = [num_unit1, num_unit2]\n",
        "\n",
        "    score_list = []\n",
        "    for i in range(sample):\n",
        "        clear_session()\n",
        "        print(f\"\\r#{trial.number:2} -- unit: {num_units}, sampling: {i+1}/{sample}\", end=\"\")\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Dense(\n",
        "                input_dim=learn_x.shape[1], units=num_units[0],\n",
        "                activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "        for i in range(len(num_units) - 1):\n",
        "            model.add(Dense(\n",
        "                input_dim=num_units[i], units=num_units[i+1],\n",
        "                activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "        model.add(Dense(input_dim=num_units[-1], units=1))\n",
        "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
        "        model.fit(learn_x, learn_y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "        score = model.evaluate(test_x, test_y, batch_size=test_x.shape[0], verbose=0)\n",
        "        score_list.append(score)\n",
        "            \n",
        "    mean, std = pd.Series(score_list).describe().loc[[\"mean\",\"std\"]]        \n",
        "    print(f\"\\r#{trial.number:2} -- unit: {num_units}, samples: {samples}/101, mean: {mean:.4e}, std: {std:.4e}\")\n",
        "\n",
        "    return mean"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPTsIqaoflro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "679f6256-8b36-41e9-9c30-a5f49a6edcbc"
      },
      "source": [
        "model_tag = \"conv.1\"\n",
        "data_path = f\"{work_path}/data/norms2\"\n",
        "\n",
        "x_index, y_index = set_index(model_tag)\n",
        "learn_list, test_list  = set_dataset_label(model_tag)\n",
        "\n",
        "dataset = DatasetClass(data_path)\n",
        "learn_x, learn_y = dataset.get_data(learn_list, x_index, y_index)\n",
        "test_x, test_y = dataset.get_data(test_list, x_index, y_index)\n",
        "\n",
        "print(f\"x_index: {x_index}, y_index: [{y_index[0]}]\")\n",
        "print(f\"learn list: {learn_list}, test_list: {test_list}\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_index: [0, 1, 2, 3, 4, 5, 6], y_index: [0]\n",
            "learn list: ms1a, test_list: ms2a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-aAo7mWYbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31dc31b7-3e4f-4140-9525-1463d325c2bf"
      },
      "source": [
        "study_label = \"ver1.2\"\n",
        "STUDY_LOADING = False\n",
        "\n",
        "storage_path = f\"sqlite:///optimize_{model_tag}.db\"\n",
        "study_name = model_tag + \"_\" + study_label\n",
        "\n",
        "# study load or create\n",
        "if STUDY_LOADING:\n",
        "    study = optuna.load_study(study_name, storage_path, pruner=optuna.pruners.MedianPruner())\n",
        "else:\n",
        "    study = optuna.create_study(study_name=study_name, storage=storage_path, direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-07-28 17:07:03,657] A new study created with name: conv.1_ver1.2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1fApkgAXtZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a46b503-7ec0-4516-e6d5-c48709ca1656"
      },
      "source": [
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"*** All Trial are finished!! ***\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0 -- unit: [58, 13], sampling: 10/31"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLSArSbX5RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}