{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimization",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heros-lab/colaboratory/blob/master/Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJLFfAg-Mvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "28622102-e2fd-4f82-dcf6-7ffe392e78bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration import KerasPruningCallback\n",
        "\n",
        "work_path = \"/content/drive/My Drive/Colab Notebooks\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.18)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna) (4.1.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.2)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna) (3.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: cmaes>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.1.3)\n",
            "Requirement already satisfied: cmd2!=0.8.3,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.4.5)\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: stevedore>=1.20.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKF3bmZZfahN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetClass:\n",
        "    def __init__(self, data_path):\n",
        "        self.path = data_path\n",
        "    \n",
        "    def __reflect_index(self, data, index):\n",
        "        if index != None:\n",
        "            data = data[:, index]\n",
        "        return data\n",
        "        \n",
        "    def __load_df(self, data_label):\n",
        "        data_x = pd.read_csv(f\"{self.path}/{data_label}_nx.csv\", index_col=0)\n",
        "        data_y = pd.read_csv(f\"{self.path}/{data_label}_ny.csv\", index_col=0)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_data(self, data_label, x_index, y_index):\n",
        "        data_x, data_y = self.__load_df(data_label)\n",
        "        data_x = self.__reflect_index(data_x.values, x_index)\n",
        "        data_y = self.__reflect_index(data_y.values, y_index)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_stack(self, dataset_list, x_index, y_index):\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_data(label, x_index, y_index)\n",
        "            if dataset_list.index(label) == 0:\n",
        "                data_x = tmp_x\n",
        "                data_y = tmp_y\n",
        "            else:\n",
        "                data_x = np.vstack((data_x, tmp_x))\n",
        "                data_y = np.vstack((data_y, tmp_y))\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def __load_dict(self, dataset_list, x_index, y_index):\n",
        "        data_x, data_y = {}, {}\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_data(label, x_index, y_index)\n",
        "            data_x[label] = tmp_x\n",
        "            data_y[label] = tmp_y\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def get_data(self, dataset_label, x_index=None, y_index=None, dict_type:bool=False):\n",
        "        if not dict_type:\n",
        "            if type(dataset_label) == str:\n",
        "                data_x, data_y = self.__load_data(dataset_label, x_index, y_index)\n",
        "            else:\n",
        "                data_x, data_y = self.__load_stack(dataset_label, x_index, y_index)\n",
        "        else:\n",
        "            data_x, data_y = self.__load_dict(dataset_label, x_index, y_index)\n",
        "        return data_x, data_y\n",
        "    \n",
        "    def get_dataframe(self, dataset_list):\n",
        "        data_x = {}\n",
        "        data_y = {}\n",
        "        for label in dataset_list:\n",
        "            tmp_x, tmp_y = self.__load_df(label)\n",
        "            data_x[label] = tmp_x\n",
        "            data_y[label] = tmp_y\n",
        "        return data_x, data_y\n",
        "\n",
        "\n",
        "def set_index(model_type):\n",
        "    if \"conv.\" in model_type:\n",
        "        x_index = [i for i in range(7)]\n",
        "    elif model_type == \"prop.1\":\n",
        "        x_index = [0,3,4,6]\n",
        "    elif model_type == \"prop.2\":\n",
        "        x_index = [1,2,5,6]\n",
        "    elif model_type == \"prop.3\":\n",
        "        x_index = [1,2,5,6]\n",
        "    elif model_type == \"prop.4\":\n",
        "        x_index = [0,3,4,5,6]\n",
        "    else:\n",
        "        print(f\"<< {model_type} >> This model is not exist.\")\n",
        "    y_index = [int(model_type[-1])-1]\n",
        "    return x_index, y_index\n",
        "\n",
        "\n",
        "def set_dataset_label(model_type):\n",
        "    type_id = int(model_type[-1])\n",
        "    if type_id == 1:\n",
        "        learn = \"ms1a\"\n",
        "        test = \"ms2a\"\n",
        "    elif type_id == 2:\n",
        "        learn = \"ms3a\"\n",
        "        test = \"ms1a\"\n",
        "    elif type_id == 3:\n",
        "        learn = \"ms2a\"\n",
        "        test = \"ms3a\"\n",
        "    elif type_id == 4:\n",
        "        learn = \"ms3a\"\n",
        "        test = \"ms1a\"\n",
        "    return learn, test\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBQfqqjojmv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    max_unit = 200\n",
        "    batch_size = 512\n",
        "    #element = \n",
        "    epochs = 200\n",
        "    sample = 101\n",
        "    \n",
        "    num_unit1 = trial.suggest_int(f\"num_unit1\", 1, max_unit)\n",
        "    #max_unit2 = int((element - learn_x.shape[1]*num_unit1)/(num_unit1 + 1)) if max_unit2 <= max_unit else max_unit\n",
        "    #num_unit2 = trial.suggest_int(f\"num_unit2\", 1, max_unit2)\n",
        "    num_unit2 = trial.suggest_int(f\"num_unit2\", 1, max_unit)\n",
        "    num_units  = [num_unit1, num_unit2]\n",
        "\n",
        "    score_list = []\n",
        "    for i in range(sample):\n",
        "        clear_session()\n",
        "        print(f\"\\r#{trial.number:2} -- unit: {num_units}, sampling: {i+1}/{sample}\", end=\"\")\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Dense(\n",
        "                input_dim=learn_x.shape[1], units=num_units[0],\n",
        "                activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "        for i in range(len(num_units) - 1):\n",
        "            model.add(Dense(\n",
        "                input_dim=num_units[i], units=num_units[i+1],\n",
        "                activation=\"tanh\", kernel_initializer=\"glorot_uniform\"))\n",
        "        model.add(Dense(input_dim=num_units[-1], units=1))\n",
        "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
        "        model.fit(learn_x, learn_y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "        score = model.evaluate(test_x, test_y, batch_size=test_x.shape[0], verbose=0)\n",
        "        score_list.append(score)\n",
        "            \n",
        "    mean, std = pd.Series(score_list).describe().loc[[\"mean\",\"std\"]]        \n",
        "    print(f\"\\r#{trial.number:2} -- unit: {num_units}, samples: {samples}/101, mean: {mean:.4e}, std: {std:.4e}\")\n",
        "\n",
        "    return mean"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLZiBtuaZBIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98b4eff9-3fb9-4223-f952-8670d23ace1b"
      },
      "source": [
        "model_tag = \"conv.1\"\n",
        "data_path = f\"{work_path}/data/norms\"\n",
        "\n",
        "x_index, y_index = set_index(model_tag)\n",
        "learn_list, test_list  = set_dataset_label(model_tag)\n",
        "\n",
        "dataset = DatasetClass(data_path)\n",
        "learn_x, learn_y = dataset.get_data(learn_list, x_index, y_index)\n",
        "test_x, test_y = dataset.get_data(test_list, x_index, y_index)\n",
        "\n",
        "print(f\"x_index: {x_index}, y_index: [{y_index[0]}]\")\n",
        "print(f\"learn list: {learn_list}, test_list: {test_list}\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_index: [0, 1, 2, 3, 4, 5, 6], y_index: [0]\n",
            "learn list: ms1a, test_list: ms2a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUbqshWSi0UX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37c4170a-11e8-4914-9a1c-9ec56623fa9d"
      },
      "source": [
        "study_label = \"ver1.0\"\n",
        "STUDY_LOADING = False\n",
        "\n",
        "storage_path = f\"sqlite:///{work_path}/optimize_{model_tag}.db\"\n",
        "study_name = model_tag + \"_\" + study_label\n",
        "\n",
        "# study load or create\n",
        "if STUDY_LOADING:\n",
        "    study = optuna.load_study(study_name, storage_path, pruner=optuna.pruners.MedianPruner())\n",
        "else:\n",
        "    study = optuna.create_study(study_name=study_name, storage=storage_path, direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[I 2020-07-19 19:33:23,068] A new study created with name: conv.1_ver1.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHoh1z78I6z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dc8b880-e7aa-414d-a163-6e0d58aab1c9"
      },
      "source": [
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"*** All Trial are finished!! ***\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0 -- unit: [136, 64], sampling: 6/101"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98euQyEEAVZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best = study.best_trial\n",
        "print(f\"#{best.number}: params={best.params}, value={best.value}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPTsIqaoflro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "study.best_trial.params"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}